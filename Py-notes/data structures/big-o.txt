In short: 
Big-O analysis enables you compare the predicted relative performance of different algorithms without having to benchmark 
them at first or implement it. 

#	How big-o works? 

In big-O analysis, 
1. input size is assumed to be 'n'. 'n' is just the size of input. It could simply represents the number of elements in an array or 'n' may represent the number of nodes in a linked list, or the number of bits in a data type, or the number of entries in a hash table, and so on.

2. Examine n : Determine how many times the n input items are examined in terms of n.
	-	Commonly, an examination might be something like adding an input value to a constant, creating a new input item, or deleting an input value. In big-O analysis, these operations are all considered equivalent
	-	 Big-O analysis yields the asymptotic running time, the limit of the running time as n gets very large. As n approaches infinity, the difference between o(n) and O(n + 2) is insignificant, so the constant term can be ignored. 

	Similarly, for an algorithm running in
	n + n^2 time, the difference between n^2 and n + n^2 is negligible for very large n. Thus, in big-O analysis you eliminate all but the highest-order term, the term that is largest as n gets very large. In this case, n is the highest-order term. Same goes for n(n/2) : this become O(n^2/2) which is counted as O(n^2)

3. The fastest-possible running time for any run-time analysis is O(1), commonly referred to as constant running time.


# How to perform big-O :
	The general procedure for big-O run-time analysis is as follows:
		1. Figure out what the input is and what n represents.
		2. Express the number of operations the algorithm performs in terms of n.
		3. Eliminate all but the highest-order terms.
		4. Remove all constant factors.


Hint: 
	If ever asked to comment on the efficiency of any algorithm. A typical big-O analysis is sufficient. 


